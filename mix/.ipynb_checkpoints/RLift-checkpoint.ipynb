{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KmVSVXeo8NS",
    "outputId": "7f5bf787-382c-496d-aa22-6f61d21f8849"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RTRnm0v-_wjx"
   },
   "outputs": [],
   "source": [
    "# !cp -r 'drive/MyDrive/x5_data' '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IbeXj8GQfNh8",
    "outputId": "d309fe02-8ff3-4eed-efe5-f9ebe5e3fc32"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-uplift\n",
    "# !pip install causalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RHdGZsOU_aNk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "from causalml.dataset import *\n",
    "\n",
    "\n",
    "df = pd.read_csv('Hillstrom.csv')\n",
    "df.drop(['history_segment', \"conversion\", \"visit\"], axis=1, inplace=True)\n",
    "\n",
    "cat_cols = ['zip_code', 'channel']\n",
    "df_ohe = pd.get_dummies(df, columns=cat_cols)\n",
    "df_ohe = df_ohe[df_ohe['segment'] != 'Mens E-Mail']\n",
    "\n",
    "df_ohe.segment = df_ohe.segment.map({'Womens E-Mail': 1,  'No E-Mail': 0})\n",
    "\n",
    "X = df_ohe.drop(['spend', 'segment'], axis=1)\n",
    "y = df_ohe['spend']\n",
    "treatment = df_ohe['segment'].astype('int')\n",
    "X, y, treatment = np.array(X), np.array(y), np.array(treatment)\n",
    "\n",
    "# y, X, treatment, tau, b, e = synthetic_data(mode=2, n=10000, p=8, sigma=1.0)\n",
    "X_train, X_test, y_train, y_test, treat_train, treat_test= train_test_split(X, y, treatment, test_size=0.33, random_state=0)\n",
    "\n",
    "train_idx, val_idx = train_test_split(np.arange(X_train.shape[0]), test_size=0.3, random_state=0)\n",
    "X_val, y_val, treat_val = X_train[val_idx], y_train[val_idx], treat_train[val_idx]\n",
    "X_train, y_train, treat_train = X_train[train_idx], y_train[train_idx], treat_train[train_idx]\n",
    "\n",
    "action_probs = np.bincount(treat_train) / len(treat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vPG6blLj_rr7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "class X5Dataset(Dataset):\n",
    "    def __init__(self, X, y, treat):\n",
    "        self.X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "        self.y = torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.treat = treat\n",
    "  \n",
    "    def __getitem__(self, id):\n",
    "        return self.X[id], self.y[id], self.treat[id]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "def collate(batch):\n",
    "    X, y, treat = zip(*batch)\n",
    "    return X, y, treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "51IIvhFjjkOU"
   },
   "outputs": [],
   "source": [
    "class PolicyGradient(nn.Module):\n",
    "    def __init__(self, n_action, n_features, hidden_dims):\n",
    "        super(PolicyGradient, self).__init__()\n",
    "\n",
    "        def get_dense_block(in_dim, out_dim):\n",
    "            return nn.Sequential(nn.Linear(in_dim, out_dim), nn.BatchNorm1d(out_dim), nn.Tanh())\n",
    "\n",
    "        blocks = [get_dense_block(n_features, hidden_dims[0])]\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            blocks.append(get_dense_block(hidden_dims[i], hidden_dims[i + 1]))\n",
    "        self.net = nn.Sequential(*blocks,\n",
    "                                nn.Linear(hidden_dims[-1], n_action))\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.net(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wKSKqQ3Cj-IO"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, action_probs, train_dataset, val_dataset, test_dataset, train_config, device, n_actions=2):\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.train_loader = DataLoader(train_dataset, \n",
    "                                       batch_size=train_config.batch_size, \n",
    "                                       drop_last=True,\n",
    "                                       shuffle=True)\n",
    "        self.val_loader = DataLoader(val_dataset,\n",
    "                                     batch_size=train_config.batch_size)\n",
    "        self.test_loader = DataLoader(test_dataset,\n",
    "                                      batch_size=train_config.batch_size)\n",
    "        self.train_config = train_config\n",
    "        self.device = device\n",
    "        self.n_actions = 2\n",
    "\n",
    "        self.action_probs = action_probs\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss(reduce=False)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=train_config.lr)\n",
    "\n",
    "    def _SN_UMG(self, records, n_actions=2):\n",
    "        \"\"\"\n",
    "        records: a sequence of [algorithm_action, actual_action, y]\n",
    "        \"\"\"\n",
    "        response_numerator = 0\n",
    "        response_denominator = 0\n",
    "        control_numerator = np.zeros(n_actions)\n",
    "        control_denominator = np.zeros(n_actions)\n",
    "\n",
    "        for alg_a, act_a, y in records:\n",
    "            if alg_a == act_a:\n",
    "                response_numerator += y / self.action_probs[act_a]\n",
    "                response_denominator += 1 / self.action_probs[act_a]\n",
    "            if act_a == 0 and alg_a > 0:\n",
    "                control_numerator[alg_a] += y / self.action_probs[0]\n",
    "                control_denominator[alg_a] += 1 / self.action_probs[0]\n",
    "\n",
    "        response = response_numerator / (response_denominator if response_denominator != 0 else 1)\n",
    "        action_control = control_numerator / np.where(control_denominator == 0, 1, control_denominator)\n",
    "\n",
    "        lift = response - control_numerator.sum() / (control_denominator.sum() if control_denominator.sum() != 0 else 1)\n",
    "\n",
    "        return lift, action_control\n",
    "\n",
    "    def _SN_UMG_GH(self, records, n_action=2):\n",
    "        n_treat = n_action - 1\n",
    "        real_prob = self.action_probs\n",
    "        algo_action_resp = {}\n",
    "        algo_total_norm = 0.0\n",
    "        algo_total_base_norm = 0.0\n",
    "        algo_treat_resp = [0.0] * n_treat\n",
    "        algo_total_resp = 0.0\n",
    "        algo_action_base = {}\n",
    "        algo_treat_base = [0.0] * n_treat\n",
    "        algo_total_base = 0.0\n",
    "        algo_treat_lift = [0.0] * n_treat\n",
    "        algo_total_lift = 0.0\n",
    "        algo_action_nums = np.array([0.0] * n_action)\n",
    "        algo_action_norm = np.array([0.0] * n_action)\n",
    "        algo_action_base_norm = np.array([0.0] * n_action)\n",
    "\n",
    "        real_action_resp = {}\n",
    "        real_treat_resp = [0.0] * n_treat\n",
    "        real_total_resp = 0.0\n",
    "        real_action_nums = np.array([0.0] * n_action)\n",
    "\n",
    "        for t in range(n_treat):\n",
    "            algo_action_resp[t] = np.array([0.0] * n_action)\n",
    "            algo_action_base[t] = np.array([0.0] * n_action)\n",
    "\n",
    "            real_action_resp[t] = np.array([0.0] * n_action)\n",
    "\n",
    "        for algo_action, real_action, resp in records:\n",
    "            algo_action_nums[algo_action] += 1\n",
    "            real_action_nums[real_action] += 1\n",
    "\n",
    "            algo_action_resp[0][algo_action] += resp * \\\n",
    "                (real_action == algo_action) / real_prob[real_action]\n",
    "            algo_treat_resp[0] += resp * \\\n",
    "                (real_action == algo_action) / real_prob[real_action]\n",
    "            algo_action_base[0][algo_action] += resp * \\\n",
    "                (real_action == 0) / real_prob[0]\n",
    "            algo_treat_base[0] += resp * \\\n",
    "                (real_action == 0) / real_prob[0]\n",
    "\n",
    "            real_action_resp[0][real_action] += resp\n",
    "            real_treat_resp += resp\n",
    "\n",
    "            algo_action_norm[algo_action] += (real_action == algo_action) * \\\n",
    "                1.0 / real_prob[real_action]\n",
    "            algo_total_norm += (real_action == algo_action) / \\\n",
    "                real_prob[real_action]\n",
    "            algo_action_base_norm[real_action] += (\n",
    "                real_action == 0) * 1.0 / real_prob[real_action]\n",
    "            algo_total_base_norm += (real_action == 0) * \\\n",
    "                1.0 / real_prob[real_action]\n",
    "\n",
    "        numSample = np.sum(algo_action_nums)\n",
    "\n",
    "        for a in range(n_action):\n",
    "            algo_action_resp[0][a] /= (algo_action_norm[a]\n",
    "                                        if algo_action_norm[a] > 0.0 else 1.0)\n",
    "            algo_action_base[0][a] /= (algo_action_norm[a]\n",
    "                                        if algo_action_norm[a] != 0.0 else 1.0)\n",
    "            real_action_resp[0][a] /= (real_action_nums[a]\n",
    "                                    if real_action_nums[a] != 0.0 else 1.0)\n",
    "        algo_treat_base[0] /= (algo_total_base_norm if algo_total_base_norm >\n",
    "                                0.0 else 1.0)\n",
    "        algo_treat_resp[0] /= (algo_total_norm if algo_total_norm >\n",
    "                                0.0 else 1.0)\n",
    "        real_treat_resp[0] /= numSample\n",
    "\n",
    "        algo_action_prob = algo_action_nums / np.sum(algo_action_nums)\n",
    "        real_action_prob = real_action_nums / np.sum(real_action_nums)\n",
    "\n",
    "        for i in range(n_treat):\n",
    "            for a in range(n_action):\n",
    "                algo_treat_lift[i] += (algo_action_resp[i][a] -\n",
    "                                       algo_action_base[i][a]) * algo_action_prob[a]\n",
    "\n",
    "        for i in range(n_treat):\n",
    "            algo_total_lift += algo_treat_lift[i]\n",
    "            algo_total_resp += algo_treat_resp[i]\n",
    "            algo_total_base += algo_treat_base[i]\n",
    "\n",
    "            real_total_resp += real_treat_resp[i]\n",
    "\n",
    "        return algo_total_lift, algo_action_base\n",
    "      \n",
    "    def _get_train_metrics(self, set_of_records, n_actions=2):\n",
    "        lifts = []\n",
    "        action_controls = []\n",
    "        for records in set_of_records:\n",
    "            lift, action_control = self._SN_UMG_GH(records, n_action=n_actions)\n",
    "            lifts.append(lift)\n",
    "            action_controls.append(action_control[0])\n",
    "\n",
    "        return lifts, np.mean(action_controls, axis=0)\n",
    "\n",
    "    def _train_epoch(self):\n",
    "        epoch_features = []\n",
    "        epoch_actions = []\n",
    "        epoch_rewards = []\n",
    "        epoch_treats = []\n",
    "        epoch_ys = []\n",
    "\n",
    "        preds = []\n",
    "        ys = []\n",
    "        treats = []\n",
    "\n",
    "        self.model.eval()\n",
    "        for X, y, treat in self.train_loader:\n",
    "            epoch_features.append(X)\n",
    "            X = X.to(device)\n",
    "\n",
    "            set_of_records = []\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X)\n",
    "                actions = torch.argmax(logits, 1)\n",
    "\n",
    "                actions = actions.cpu().numpy()\n",
    "                treat = treat.numpy()\n",
    "                y = y.numpy()\n",
    "\n",
    "                preds.extend(actions)\n",
    "                treats.extend(treat)\n",
    "                ys.extend(y)\n",
    "\n",
    "                records = list(zip(actions, treat, y))\n",
    "                set_of_records.append(records)\n",
    "\n",
    "                epoch_ys.append(y)\n",
    "                epoch_actions.append(actions)\n",
    "                epoch_treats.append(treat)\n",
    "\n",
    "        lifts, action_control = self._get_train_metrics(set_of_records, self.n_actions)\n",
    "        avg_lift = np.mean(lifts)\n",
    "\n",
    "        sn_umg = self._SN_UMG_GH([record for records in set_of_records for record in records], n_action=self.n_actions)[0]\n",
    "\n",
    "        print(f'Train SN-UMG: {round(sn_umg, 4)}')\n",
    "\n",
    "        for X, y, treat, actions, lift in zip(epoch_features, epoch_ys, epoch_treats, epoch_actions, lifts):\n",
    "            rewards = np.zeros(len(X))\n",
    "            for a in range(self.n_actions):\n",
    "                a_control = action_control[a]\n",
    "\n",
    "                marker = ((actions == a) & (actions == treat)).astype(np.int16)\n",
    "                rewards += marker * ((y - a_control) + lift - avg_lift)\n",
    "                marker = ((treat == 0) & (actions == a) & (a > 0)).astype(np.int16)\n",
    "                rewards += marker * (-(y - a_control) + lift - avg_lift)\n",
    "            epoch_rewards.append(torch.Tensor(rewards))\n",
    "\n",
    "        self.model.train()\n",
    "        for X, actions, rewards in zip(epoch_features, epoch_actions, epoch_rewards):\n",
    "            bs = X.size(0)\n",
    "            X = X.to(device)\n",
    "            logits = self.model(X)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            entropy = (-probs * torch.log(probs)).sum(-1).mean()\n",
    "\n",
    "            minus_log_prob = -torch.log(probs[torch.arange(bs), actions])\n",
    "            entropy = (torch.log(probs) * probs).mean(1)\n",
    "            loss = (minus_log_prob * rewards + entropy).mean()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "  \n",
    "    def validate(self):\n",
    "        preds = []\n",
    "        ys = []\n",
    "        treats = []\n",
    "\n",
    "        records = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y, treat in self.val_loader:\n",
    "                logits = self.model(X)\n",
    "                probs = torch.softmax(logits, 1)\n",
    "                actions = torch.argmax(logits, 1).cpu().numpy()\n",
    "\n",
    "                treat = treat.cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "\n",
    "                preds.extend(probs[:, 1].cpu().numpy())\n",
    "                ys.extend(y)\n",
    "                treats.extend(treat)\n",
    "\n",
    "                batch_records = list(zip(actions, treat, y))\n",
    "                records.extend(batch_records)\n",
    "\n",
    "        sn_umg = self._SN_UMG_GH(records, self.n_actions)[0]\n",
    "\n",
    "        print(f'Val SN-UMG: {round(sn_umg, 4)}\\n')\n",
    "\n",
    "        return sn_umg\n",
    "  \n",
    "    def train(self):\n",
    "        best_score = 0\n",
    "        best_params = None\n",
    "\n",
    "        for epoch in range(self.train_config.epochs):\n",
    "            print(f'Epoch #{epoch + 1}:')\n",
    "            self._train_epoch()\n",
    "            score = self.validate()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "        self.model.load_state_dict(best_params)\n",
    "\n",
    "    def test(self):\n",
    "        preds = []\n",
    "        ys = []\n",
    "        treats = []\n",
    "\n",
    "        records = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y, treat in self.test_loader:\n",
    "                logits = self.model(X)\n",
    "                probs = torch.softmax(logits, 1)\n",
    "                actions = torch.argmax(logits, 1).cpu().numpy()\n",
    "\n",
    "                treat = treat.cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "\n",
    "                preds.extend(probs[:, 1].cpu().numpy())\n",
    "                ys.extend(y)\n",
    "                treats.extend(treat)\n",
    "\n",
    "                batch_records = list(zip(actions, treat, y))\n",
    "                records.extend(batch_records)\n",
    "\n",
    "        sn_umg = self._SN_UMG_GH(records, self.n_actions)[0]\n",
    "\n",
    "        print(f'\\nTest SN-UMG: {round(sn_umg, 4)}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "y0sg9NRLybEb"
   },
   "outputs": [],
   "source": [
    "class TrainConfig:\n",
    "    epochs = 5\n",
    "    lr = 1e-4\n",
    "    batch_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-e_H5Y-5v2Sn"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(38)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = PolicyGradient(2, 11, [20, 15, 5])\n",
    "trainer = Trainer(model, \n",
    "                  action_probs, \n",
    "                  X5Dataset(X_train, y_train, treat_train), \n",
    "                  X5Dataset(X_val, y_val, treat_val),\n",
    "                  X5Dataset(X_test, y_test, treat_test),\n",
    "                  TrainConfig(), \n",
    "                  device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S78JdC9aH4MR",
    "outputId": "230454eb-5186-4f5c-9ba3-c5fcbb0ced6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1:\n",
      "Train SN-UMG: 0.0\n",
      "Val SN-UMG: 0.0\n",
      "\n",
      "Epoch #2:\n",
      "Train SN-UMG: 0.0\n",
      "Val SN-UMG: 0.0\n",
      "\n",
      "Epoch #3:\n",
      "Train SN-UMG: 0.0\n",
      "Val SN-UMG: 0.0\n",
      "\n",
      "Epoch #4:\n",
      "Train SN-UMG: 0.0\n",
      "Val SN-UMG: 0.0\n",
      "\n",
      "Epoch #5:\n",
      "Train SN-UMG: 0.0\n",
      "Val SN-UMG: 0.0\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-91f35c18e650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2c5cdd4b83e4>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_metadata'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m             \u001b[1;31m# mypy isn't aware that \"_metadata\" exists in state_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7lJ8La5yraQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RLift.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
